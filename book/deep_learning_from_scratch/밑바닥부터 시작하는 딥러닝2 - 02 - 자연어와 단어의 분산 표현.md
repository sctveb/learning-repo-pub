# 밑바닥부터 시작하는 딥러닝2 - 02 - 자연어와 단어의 분산 표현

## 자연어 처리란

사라밍 사용하는 말을 컴퓨터에게 이해시키는 기술

## 시소러스

유의어 집합을 만들고 단어들의 관계를 그래프로 표현

WordNet : 대표적인 시소러스

단점

1. 시대 변화에 대응하기 어렵다
2. 인적 자원 비용이 크다
3. 단어의 미묘한 차이를 표현할 수 없다



## 통계 기반 기법

단어의 분산 표현 : 단어가 가지는 애매한 표현을 고정 길이의 밀집벡터로 수치화 시킨 것 (like 가무잡잡 -> RGB #888888)

분포 가설 : `단어의 의미는 주변 단어에 의해 형성된다`는 개념에서 비롯된 자연어 분석 가설, 이 가설에선 맥락을 특정 단어를 중심에 둔 주변 단어를 말함, 그리고 맥락의 크기를 윈도우 크기

동시발생 행렬 : 전처리된 말뭉치(corpus)

벡터간 유사도 : 벡터 사이의 유사도를 측정하는 방법은 여러가지가 있지만 단어 벡터의 유사도를 나타낼 때는 코사인 유사도를 자주 이용함



## 통계 기반 기법 개선하기

상호정보량 : 발생 횟수로 판별하기에는 적절하지 않음 많이 사용되는 관사 등이 연관되어 부적합한 결과를 초래할 수 있음. 그렇기에 `점별 상호정보량`이라는 척도를 사용함.  좋은 결과를 얻을 수 있지만 두 단어의 동시발생 횟수가 0이면 음의 무한이 되기 때문에 `양의 상호정보량`을 사용. 말뭉치가 많아질 경우 벡터의 차원이 기하급수적으로 증가하기 때문에 차원 감소가 필요함.

차원 감소 : 중요한 정보를 최대한 유지하면서 차원을 줄이기 위해서는 데이터의 특성을 나타내는 저차원값을 알아내야 함. 이를 위한 방법으로 `특잇값분해(SVD)`를 사용함.

SVD에 의한 차원 감소 :

PTB 데이터셋 : 